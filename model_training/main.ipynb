{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SentinelForge\n",
    "\n",
    "#### This is the start of training file for SentinelForge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['main.c', 'main.cpp', 'main_0.c', 'main_1.c', 'main_10.c', 'main_100.c', 'main_101.c', 'main_102.c', 'main_103.c', 'main_104.c', 'main_105.c', 'main_106.c', 'main_107.c', 'main_108.c', 'main_109.c', 'main_11.c', 'main_110.c', 'main_111.c', 'main_112.c', 'main_113.c', 'main_114.c', 'main_115.c', 'main_116.c', 'main_117.c', 'main_118.c', 'main_119.c', 'main_12.c', 'main_120.c', 'main_121.c', 'main_122.c', 'main_123.c', 'main_124.c', 'main_125.c', 'main_126.c', 'main_127.c', 'main_128.c', 'main_129.c', 'main_13.c', 'main_130.c', 'main_131.c', 'main_132.c', 'main_133.c', 'main_134.c', 'main_135.c', 'main_136.c', 'main_137.c', 'main_138.c', 'main_139.c', 'main_14.c', 'main_140.c', 'main_141.c', 'main_142.c', 'main_143.c', 'main_144.c', 'main_145.c', 'main_146.c', 'main_147.c', 'main_148.c', 'main_149.c', 'main_15.c', 'main_150.c', 'main_151.c', 'main_152.c', 'main_153.c', 'main_154.c', 'main_155.c', 'main_156.c', 'main_157.c', 'main_158.c', 'main_159.c', 'main_16.c', 'main_160.c', 'main_161.c', 'main_162.c', 'main_163.c', 'main_164.c', 'main_165.c', 'main_166.c', 'main_167.c', 'main_168.c', 'main_169.c', 'main_17.c', 'main_170.c', 'main_171.c', 'main_172.c', 'main_173.c', 'main_174.c', 'main_175.c', 'main_176.c', 'main_177.c', 'main_178.c', 'main_179.c', 'main_18.c', 'main_180.c', 'main_181.c', 'main_182.c', 'main_183.c', 'main_184.c', 'main_185.c', 'main_186.c', 'main_187.c', 'main_188.c', 'main_189.c', 'main_19.c', 'main_190.c', 'main_191.c', 'main_192.c', 'main_193.c', 'main_194.c', 'main_195.c', 'main_196.c', 'main_197.c', 'main_198.c', 'main_199.c', 'main_2.c', 'main_20.c', 'main_200.c', 'main_201.c', 'main_202.c', 'main_203.c', 'main_204.c', 'main_205.c', 'main_206.c', 'main_207.c', 'main_208.c', 'main_209.c', 'main_21.c', 'main_210.c', 'main_211.c', 'main_212.c', 'main_213.c', 'main_214.c', 'main_215.c', 'main_216.c', 'main_217.c', 'main_218.c', 'main_219.c', 'main_22.c', 'main_220.c', 'main_221.c', 'main_222.c', 'main_223.c', 'main_224.c', 'main_225.c', 'main_226.c', 'main_227.c', 'main_228.c', 'main_229.c', 'main_23.c', 'main_230.c', 'main_231.c', 'main_232.c', 'main_233.c', 'main_234.c', 'main_235.c', 'main_236.c', 'main_237.c', 'main_238.c', 'main_239.c', 'main_24.c', 'main_240.c', 'main_241.c', 'main_242.c', 'main_243.c', 'main_244.c', 'main_245.c', 'main_246.c', 'main_247.c', 'main_248.c', 'main_249.c', 'main_25.c', 'main_250.c', 'main_251.c', 'main_252.c', 'main_253.c', 'main_254.c', 'main_255.c', 'main_256.c', 'main_257.c', 'main_258.c', 'main_259.c', 'main_26.c', 'main_260.c', 'main_261.c', 'main_262.c', 'main_263.c', 'main_264.c', 'main_265.c', 'main_266.c', 'main_267.c', 'main_268.c', 'main_269.c', 'main_27.c', 'main_270.c', 'main_271.c', 'main_272.c', 'main_273.c', 'main_274.c', 'main_275.c', 'main_276.c', 'main_277.c', 'main_278.c', 'main_279.c', 'main_28.c', 'main_280.c', 'main_281.c', 'main_282.c', 'main_283.c', 'main_284.c', 'main_285.c', 'main_286.c', 'main_287.c', 'main_288.c', 'main_289.c', 'main_29.c', 'main_290.c', 'main_291.c', 'main_292.c', 'main_293.c', 'main_294.c', 'main_295.c', 'main_296.c', 'main_297.c', 'main_298.c', 'main_299.c', 'main_3.c', 'main_30.c', 'main_300.c', 'main_301.c', 'main_302.c', 'main_303.c', 'main_304.c', 'main_305.c', 'main_306.c', 'main_307.c', 'main_308.c', 'main_309.c', 'main_31.c', 'main_310.c', 'main_311.c', 'main_312.c', 'main_313.c', 'main_314.c', 'main_315.c', 'main_316.c', 'main_317.c', 'main_318.c', 'main_319.c', 'main_32.c', 'main_320.c', 'main_321.c', 'main_322.c', 'main_323.c', 'main_324.c', 'main_325.c', 'main_326.c', 'main_327.c', 'main_328.c', 'main_329.c', 'main_33.c', 'main_330.c', 'main_331.c', 'main_332.c', 'main_333.c', 'main_334.c', 'main_335.c', 'main_336.c', 'main_337.c', 'main_338.c', 'main_339.c', 'main_34.c', 'main_340.c', 'main_341.c', 'main_342.c', 'main_343.c', 'main_344.c', 'main_345.c', 'main_346.c', 'main_347.c', 'main_348.c', 'main_349.c', 'main_35.c', 'main_350.c', 'main_351.c', 'main_352.c', 'main_353.c', 'main_354.c', 'main_355.c', 'main_356.c', 'main_357.c', 'main_358.c', 'main_359.c', 'main_36.c', 'main_360.c', 'main_361.c', 'main_362.c', 'main_363.c', 'main_364.c', 'main_365.c', 'main_366.c', 'main_367.c', 'main_368.c', 'main_369.c', 'main_37.c', 'main_370.c', 'main_371.c', 'main_372.c', 'main_373.c', 'main_374.c', 'main_375.c', 'main_376.c', 'main_377.c', 'main_378.c', 'main_379.c', 'main_38.c', 'main_380.c', 'main_381.c', 'main_382.c', 'main_383.c', 'main_384.c', 'main_385.c', 'main_386.c', 'main_387.c', 'main_388.c', 'main_389.c', 'main_39.c', 'main_390.c', 'main_391.c', 'main_392.c', 'main_393.c', 'main_394.c', 'main_395.c', 'main_396.c', 'main_397.c', 'main_398.c', 'main_399.c', 'main_4.c', 'main_40.c', 'main_400.c', 'main_401.c', 'main_402.c', 'main_403.c', 'main_404.c', 'main_405.c', 'main_406.c', 'main_407.c', 'main_408.c', 'main_409.c', 'main_41.c', 'main_410.c', 'main_411.c', 'main_412.c', 'main_413.c', 'main_414.c', 'main_415.c', 'main_416.c', 'main_417.c', 'main_418.c', 'main_419.c', 'main_42.c', 'main_420.c', 'main_421.c', 'main_422.c', 'main_423.c', 'main_424.c', 'main_425.c', 'main_426.c', 'main_427.c', 'main_428.c', 'main_429.c', 'main_43.c', 'main_430.c', 'main_431.c', 'main_432.c', 'main_433.c', 'main_434.c', 'main_435.c', 'main_436.c', 'main_437.c', 'main_438.c', 'main_439.c', 'main_44.c', 'main_440.c', 'main_441.c', 'main_442.c', 'main_443.c', 'main_444.c', 'main_445.c', 'main_446.c', 'main_447.c', 'main_448.c', 'main_449.c', 'main_45.c', 'main_450.c', 'main_451.c', 'main_452.c', 'main_453.c', 'main_454.c', 'main_455.c', 'main_456.c', 'main_457.c', 'main_458.c', 'main_459.c', 'main_46.c', 'main_460.c', 'main_461.c', 'main_462.c', 'main_463.c', 'main_464.c', 'main_465.c', 'main_466.c', 'main_467.c', 'main_468.c', 'main_469.c', 'main_47.c', 'main_470.c', 'main_471.c', 'main_472.c', 'main_473.c', 'main_474.c', 'main_475.c', 'main_476.c', 'main_477.c', 'main_478.c', 'main_479.c', 'main_48.c', 'main_480.c', 'main_481.c', 'main_482.c', 'main_483.c', 'main_484.c', 'main_485.c', 'main_486.c', 'main_487.c', 'main_488.c', 'main_489.c', 'main_49.c', 'main_490.c', 'main_491.c', 'main_492.c', 'main_493.c', 'main_494.c', 'main_495.c', 'main_496.c', 'main_497.c', 'main_498.c', 'main_499.c', 'main_5.c', 'main_50.c', 'main_51.c', 'main_52.c', 'main_53.c', 'main_54.c', 'main_55.c', 'main_56.c', 'main_57.c', 'main_58.c', 'main_59.c', 'main_6.c', 'main_60.c', 'main_61.c', 'main_62.c', 'main_63.c', 'main_64.c', 'main_65.c', 'main_66.c', 'main_67.c', 'main_68.c', 'main_69.c', 'main_7.c', 'main_70.c', 'main_71.c', 'main_72.c', 'main_73.c', 'main_74.c', 'main_75.c', 'main_76.c', 'main_77.c', 'main_78.c', 'main_79.c', 'main_8.c', 'main_80.c', 'main_81.c', 'main_82.c', 'main_83.c', 'main_84.c', 'main_85.c', 'main_86.c', 'main_87.c', 'main_88.c', 'main_89.c', 'main_9.c', 'main_90.c', 'main_91.c', 'main_92.c', 'main_93.c', 'main_94.c', 'main_95.c', 'main_96.c', 'main_97.c', 'main_98.c', 'main_99.c', 'main_init.cpp', 'main_only_p.c']\n"
     ]
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "\n",
    "data_path = os.path.join(current_dir, '..\\data')\n",
    "\n",
    "data_path_filtered = [file for file in os.listdir(data_path) if file.endswith((\".c\", \".cpp\"))]\n",
    "print(data_path_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test opening one file to check on its content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileAST: \n",
      "  FuncDef: \n",
      "    Decl: main, [], [], [], []\n",
      "      FuncDecl: \n",
      "        TypeDecl: main, [], None\n",
      "          IdentifierType: ['int']\n",
      "    Compound: \n",
      "      Decl: string, [], [], [], []\n",
      "        PtrDecl: []\n",
      "          TypeDecl: string, [], None\n",
      "            IdentifierType: ['char']\n",
      "      Assignment: =\n",
      "        ID: string\n",
      "        Cast: \n",
      "          Typename: None, [], None\n",
      "            PtrDecl: []\n",
      "              TypeDecl: None, [], None\n",
      "                IdentifierType: ['char']\n",
      "          FuncCall: \n",
      "            ID: malloc\n",
      "            ExprList: \n",
      "              BinaryOp: *\n",
      "                UnaryOp: sizeof\n",
      "                  Typename: None, [], None\n",
      "                    TypeDecl: None, [], None\n",
      "                      IdentifierType: ['char']\n",
      "                Constant: int, 1000\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(data_path,data_path_filtered[0])\n",
    "\n",
    "# Read the file content into a string\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    code = f.read()\n",
    "\n",
    "# Remove preprocessor directives (lines starting with #)\n",
    "filtered_code = \"\\n\".join(line for line in code.splitlines() if not line.strip().startswith(\"#\"))\n",
    "\n",
    "# Parse the code using pycparser\n",
    "parser = CParser()\n",
    "ast = parser.parse(filtered_code)\n",
    "\n",
    "# Display the AST\n",
    "ast.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supportive C Parser function to generate AST for each C file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycparser import CParser\n",
    "\n",
    "def parse_c_code_to_ast(code):\n",
    "    filtered_code = \"\\n\".join(line for line in code.splitlines() if not line.strip().startswith(\"#\"))\n",
    "\n",
    "# Parse the code using pycparser\n",
    "    parser = CParser()\n",
    "    ast = parser.parse(filtered_code)\n",
    "    return ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycparser\n",
    "\n",
    "\n",
    "def extract_features_from_ast(ast):\n",
    "    features = {}\n",
    "\n",
    "    def traverse_ast(node, depth=0):\n",
    "        if node is not None:\n",
    "            node_type = type(node).__name__\n",
    "\n",
    "            # Feature 1: Track the count of node types\n",
    "            # if node_type not in features:\n",
    "            #     features[node_type] = 0\n",
    "            # features[node_type] += 1\n",
    "\n",
    "            # Feature 2: Extract details of variable declarations (Decl) and function declarations (FuncDecl)\n",
    "            if node_type == 'Decl':\n",
    "                var_name = node.name  # Get the variable name\n",
    "                var_type = None\n",
    "\n",
    "                # If it's a simple type (e.g., 'char', 'int')\n",
    "                if isinstance(node.type, pycparser.c_ast.TypeDecl):\n",
    "                    var_type = node.type.type.names[0] if node.type.type else None\n",
    "                \n",
    "                # If it's a pointer type (e.g., 'char*')\n",
    "                if isinstance(node.type, pycparser.c_ast.PtrDecl):\n",
    "                    # Traverse the underlying TypeDecl to get the base type\n",
    "                    if isinstance(node.type.type, pycparser.c_ast.TypeDecl):\n",
    "                        base_type = node.type.type.type.names[0] if node.type.type.type else None\n",
    "                        var_type = f'pointer to {base_type}'\n",
    "                \n",
    "                # If it's an array type (e.g., 'char[]')\n",
    "                if isinstance(node.type, pycparser.c_ast.ArrayDecl):\n",
    "                    # Traverse the underlying TypeDecl to get the base type\n",
    "                    if isinstance(node.type.type, pycparser.c_ast.TypeDecl):\n",
    "                        base_type = node.type.type.type.names[0] if node.type.type.type else None\n",
    "                        var_type = f'array to {base_type}'\n",
    "                    \n",
    "                    # Extract initialization values (if any)\n",
    "                    if isinstance(node.init, pycparser.c_ast.InitList):\n",
    "                        features[f'{var_name}_init'] = \"Yes\"\n",
    "                    else:\n",
    "                        features[f'{var_name}_init'] = \"No\"\n",
    "\n",
    "                # Add the variable and its type to the list\n",
    "                if var_type:\n",
    "                    features['string'] = var_type\n",
    "\n",
    "\n",
    "\n",
    "            if node_type == 'FuncDef':\n",
    "                # Extract the function name\n",
    "                func_name = node.decl.name\n",
    "                features[f'func_{func_name}_defined'] = 1  # To track the presence of the function definition\n",
    "                # Extract function's return type and parameters\n",
    "                func_return_type = None\n",
    "                if isinstance(node.decl.type, pycparser.c_ast.FuncDecl):\n",
    "                    return_type = node.decl.type.type\n",
    "                    if isinstance(return_type, pycparser.c_ast.TypeDecl):\n",
    "                        func_return_type = return_type.type.names if return_type.type else None\n",
    "                #features[f'func_{func_name}_return_type'] = func_return_type\n",
    "\n",
    "            # Feature 3: Extract function calls like malloc\n",
    "            if node_type == 'FuncCall':\n",
    "                func_name = node.name.name  # Function name (e.g., malloc)\n",
    "                if func_name == 'malloc':\n",
    "                    features['malloc_used'] = 1  # Track if malloc is used\n",
    "\n",
    "            # Recursively visit child nodes\n",
    "            for field, child in node.children():\n",
    "                traverse_ast(child, depth + 1)\n",
    "\n",
    "    traverse_ast(ast)\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TRUNG\\Desktop\\file_backup_dual_boot\\Coding\\1.C++\\iNTUition_dummy\\model_training\\..\\data\\main.c\n",
      "FileAST: \n",
      "  FuncDef: \n",
      "    Decl: main, [], [], [], []\n",
      "      FuncDecl: \n",
      "        TypeDecl: main, [], None\n",
      "          IdentifierType: ['int']\n",
      "    Compound: \n",
      "      Decl: string, [], [], [], []\n",
      "        PtrDecl: []\n",
      "          TypeDecl: string, [], None\n",
      "            IdentifierType: ['char']\n",
      "      Assignment: =\n",
      "        ID: string\n",
      "        Cast: \n",
      "          Typename: None, [], None\n",
      "            PtrDecl: []\n",
      "              TypeDecl: None, [], None\n",
      "                IdentifierType: ['char']\n",
      "          FuncCall: \n",
      "            ID: malloc\n",
      "            ExprList: \n",
      "              BinaryOp: *\n",
      "                UnaryOp: sizeof\n",
      "                  Typename: None, [], None\n",
      "                    TypeDecl: None, [], None\n",
      "                      IdentifierType: ['char']\n",
      "                Constant: int, 1000\n",
      "{'func_main_defined': 1, 'string': 'pointer to char', 'malloc_used': 1}\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(data_path,data_path_filtered[0])\n",
    "print(file_path)\n",
    "\n",
    "# Read the file content into a string\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    code = f.read()\n",
    "\n",
    "ast = parse_c_code_to_ast(code)\n",
    "features = extract_features_from_ast(ast)\n",
    "\n",
    "ast.show()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TRUNG\\Desktop\\file_backup_dual_boot\\Coding\\1.C++\\iNTUition_dummy\\model_training\\..\\data\\main_only_p.c\n",
      "FileAST: \n",
      "  FuncDef: \n",
      "    Decl: main, [], [], [], []\n",
      "      FuncDecl: \n",
      "        TypeDecl: main, [], None\n",
      "          IdentifierType: ['int']\n",
      "    Compound: \n",
      "      Decl: string, [], [], [], []\n",
      "        PtrDecl: []\n",
      "          TypeDecl: string, [], None\n",
      "            IdentifierType: ['char']\n",
      "{'func_main_defined': 1, 'string': 'pointer to char'}\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(data_path, 'main_only_p.c')\n",
    "print(file_path)\n",
    "\n",
    "# Read the file content into a string\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    code = f.read()\n",
    "\n",
    "ast = parse_c_code_to_ast(code)\n",
    "features = extract_features_from_ast(ast)\n",
    "\n",
    "ast.show()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TRUNG\\Desktop\\file_backup_dual_boot\\Coding\\1.C++\\iNTUition_dummy\\model_training\\..\\data\\main_init.cpp\n",
      "FileAST: \n",
      "  FuncDef: \n",
      "    Decl: main, [], [], [], []\n",
      "      FuncDecl: \n",
      "        TypeDecl: main, [], None\n",
      "          IdentifierType: ['int']\n",
      "    Compound: \n",
      "      Decl: string, [], [], [], []\n",
      "        ArrayDecl: []\n",
      "          TypeDecl: string, [], None\n",
      "            IdentifierType: ['char']\n",
      "          Constant: int, 1000\n",
      "{'func_main_defined': 1, 'string_init': 'No', 'string': 'array to char'}\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(data_path, 'main_init.cpp')\n",
    "print(file_path)\n",
    "\n",
    "# Read the file content into a string\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    code = f.read()\n",
    "\n",
    "ast = parse_c_code_to_ast(code)\n",
    "features = extract_features_from_ast(ast)\n",
    "\n",
    "ast.show()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\TRUNG\\Desktop\\file_backup_dual_boot\\Coding\\1.C++\\iNTUition_dummy\\model_training\\..\\data\\main.cpp\n",
      "FileAST: \n",
      "  FuncDef: \n",
      "    Decl: main, [], [], [], []\n",
      "      FuncDecl: \n",
      "        TypeDecl: main, [], None\n",
      "          IdentifierType: ['int']\n",
      "    Compound: \n",
      "      Decl: string, [], [], [], []\n",
      "        ArrayDecl: []\n",
      "          TypeDecl: string, [], None\n",
      "            IdentifierType: ['char']\n",
      "          Constant: int, 1000\n",
      "        InitList: \n",
      "          Constant: char, 'h'\n",
      "          Constant: char, 'e'\n",
      "          Constant: char, 'l'\n",
      "          Constant: char, 'l'\n",
      "          Constant: char, 'o'\n",
      "{'func_main_defined': 1, 'string_init': 'Yes', 'string': 'array to char'}\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(data_path,data_path_filtered[1])\n",
    "print(file_path)\n",
    "\n",
    "# Read the file content into a string\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    code = f.read()\n",
    "\n",
    "ast = parse_c_code_to_ast(code)\n",
    "features = extract_features_from_ast(ast)\n",
    "\n",
    "ast.show()\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pycparser import parse_file\n",
    "\n",
    "# Load the JSON file with labels\n",
    "with open('data.json', 'r') as f:\n",
    "    labeled_data = json.load(f)\n",
    "\n",
    "# Prepare the dataset\n",
    "X = []  # Feature matrix\n",
    "y = []  # Labels\n",
    "\n",
    "# Class labels (you can map your error types to numerical values)\n",
    "label_map = {\n",
    "    \"UNALLOCATED_POINTER\": 0,\n",
    "    \"MEMORY_NOT_FREE\": 1,\n",
    "    \"UNUSED_VARIABLE\": 2,\n",
    "    \"NONE\": 3,\n",
    "    \"OTHERS\": 4\n",
    "}\n",
    "\n",
    "# Loop through each file and process it\n",
    "data_path = data_path_filtered\n",
    "for entry in labeled_data:\n",
    "    file_name = entry[\"file\"]\n",
    "    error_type = entry[\"error\"]\n",
    "    \n",
    "    # Map the error type to a class label\n",
    "    label = label_map.get(error_type, 4)  # Default to 'Other error' if not found\n",
    "    \n",
    "    # Read the C code from the file\n",
    "    with open(file_name, 'r') as f:\n",
    "        c_code = f.read()\n",
    "\n",
    "    # Parse the C code into an AST\n",
    "    try:\n",
    "        ast = parse_c_code_to_ast(c_code)\n",
    "        features = extract_features_from_ast(ast)\n",
    "        X.append(features)  # Add features to the dataset\n",
    "        y.append(label)  # Add label to the target vector\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {file_name}: {e}\")\n",
    "        continue  # Skip files that can't be parsed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[0;32m     15\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:360\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 360\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[0;32m    370\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[0;32m    373\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2961\u001b[0m, in \u001b[0;36mvalidate_data\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2959\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m   2960\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2961\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m   2962\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m   2964\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1370\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m     )\n\u001b[0;32m   1368\u001b[0m ensure_all_finite \u001b[38;5;241m=\u001b[39m _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[1;32m-> 1370\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1373\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1387\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1389\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1055\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1053\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1054\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1055\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1057\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1058\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1059\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\_array_api.py:839\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    837\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 839\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'dict'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
